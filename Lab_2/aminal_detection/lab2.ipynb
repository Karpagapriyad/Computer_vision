{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (8.1.1)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from ultralytics) (3.8.2)\n",
      "Requirement already satisfied: numpy>=1.22.2 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from ultralytics) (1.24.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from ultralytics) (4.8.1.78)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from ultralytics) (10.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from ultralytics) (1.11.4)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from ultralytics) (2.1.2)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from ultralytics) (0.16.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from ultralytics) (4.66.1)\n",
      "Requirement already satisfied: psutil in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from ultralytics) (2.1.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from ultralytics) (0.13.1)\n",
      "Requirement already satisfied: hub-sdk>=0.0.2 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from ultralytics) (0.0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
      "Requirement already satisfied: filelock in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2023.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sparrow',\n",
       " 'cat',\n",
       " 'butterfly',\n",
       " '.DS_Store',\n",
       " 'dog',\n",
       " 'pigeon',\n",
       " 'parrot',\n",
       " 'squirrel',\n",
       " 'cow']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = '/Users/karpagapriyadhanraj/Desktop/EPITA/Computer vision/Computer_vision/Lab_2/aminal_detection/data/animals'\n",
    "os.listdir(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/Users/karpagapriyadhanraj/Desktop/EPITA/Computer vision/Computer_vision/Lab_2/aminal_detection/images/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m labeltestpath\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(curr_path,\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[39m# Creating directories for all paths defined\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m os\u001b[39m.\u001b[39;49mmakedirs(imgtrainpath)\n\u001b[1;32m     13\u001b[0m os\u001b[39m.\u001b[39mmakedirs(imgvalpath)\n\u001b[1;32m     14\u001b[0m os\u001b[39m.\u001b[39mmakedirs(imgtestpath)\n",
      "File \u001b[0;32m~/miniconda3/envs/computer-vision/lib/python3.10/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     mkdir(name, mode)\n\u001b[1;32m    226\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[39m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[39m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m exist_ok \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39misdir(name):\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/Users/karpagapriyadhanraj/Desktop/EPITA/Computer vision/Computer_vision/Lab_2/aminal_detection/images/train'"
     ]
    }
   ],
   "source": [
    "# Creating paths for separate images and labels\n",
    "curr_path=os.getcwd()\n",
    "imgtrainpath = os.path.join(curr_path,'images','train')\n",
    "imgvalpath=os.path.join(curr_path,'images','validation')\n",
    "imgtestpath=os.path.join(curr_path,'images','test')\n",
    "\n",
    "labeltrainpath=os.path.join(curr_path,'labels','train')\n",
    "labelvalpath=os.path.join(curr_path,'labels','validation')\n",
    "labeltestpath=os.path.join(curr_path,'labels','test')\n",
    "\n",
    "# Creating directories for all paths defined\n",
    "os.makedirs(imgtrainpath)\n",
    "os.makedirs(imgvalpath)\n",
    "os.makedirs(imgtestpath)\n",
    "os.makedirs(labeltrainpath)\n",
    "os.makedirs(labelvalpath)\n",
    "os.makedirs(labeltestpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname in os.listdir(datapath):\n",
    "    dirpath=os.path.join(datapath, dirname)\n",
    "    if os.path.isdir(dirpath):\n",
    "        for file in os.listdir(dirpath):\n",
    "            filepath=os.path.join(dirpath, file)\n",
    "            newname=dirname+'_'+file\n",
    "            if file.endswith((\".txt\")): # if label file, take it to label train path\n",
    "                shutil.copy(filepath, labeltrainpath)\n",
    "                path=os.path.join(labeltrainpath, file)\n",
    "                newpath=os.path.join(labeltrainpath, newname)\n",
    "            elif file.endswith((\".jpg\", \".JPG\")): # if image file, resize and take it to image train path\n",
    "                img_resized=cv2.resize(cv2.imread(filepath), (image_size, image_size))\n",
    "                path=os.path.join(imgtrainpath, file)\n",
    "                cv2.imwrite(path, img_resized)\n",
    "                newpath=os.path.join(imgtrainpath, newname)\n",
    "            os.rename(path, newpath) # Rename the file (label or image)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(imgtrainpath)), len(os.listdir(labeltrainpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_all_elements_same(lst):\n",
    "    if not lst:\n",
    "        return True  # An empty list is considered to have all elements the same.\n",
    "\n",
    "    first_element = lst[0]\n",
    "    for element in lst[1:]:\n",
    "        if element != first_element:\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m classes_list\u001b[39m=\u001b[39m[]\n\u001b[1;32m      3\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(labeltrainpath, file), \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m----> 4\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m         class_id,_,_,_,_\u001b[39m=\u001b[39mline\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m         classes_list\u001b[39m.\u001b[39mappend(class_id) \u001b[39m# creating list of all unique animal types in given image\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/computer-vision/lib/python3.10/codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[39m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m+\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m--> 322\u001b[0m     (result, consumed) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer_decode(data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors, final)\n\u001b[1;32m    323\u001b[0m     \u001b[39m# keep undecoded input until the next call\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m=\u001b[39m data[consumed:]\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(labeltrainpath):\n",
    "    classes_list=[]\n",
    "    with open(os.path.join(labeltrainpath, file), \"r\") as f:\n",
    "        for line in f:\n",
    "            class_id,_,_,_,_=line.strip().split(\" \")\n",
    "            classes_list.append(class_id) # creating list of all unique animal types in given image\n",
    "            \n",
    "    # Checking if different types of animals are present in image\n",
    "    if not are_all_elements_same(classes_list): \n",
    "        filepath=os.path.join(labeltrainpath, file)\n",
    "        newpath=os.path.join(labeltestpath, file)\n",
    "        shutil.move(filepath, newpath) # moving label file to test path\n",
    "        basename=os.path.splitext(file)[0]\n",
    "        print(basename) # printing the image name\n",
    "        imgfilename=basename+'.jpg'\n",
    "        oldimgfilepath=os.path.join(imgtrainpath, imgfilename)\n",
    "        newimgfilepath=os.path.join(imgtestpath, imgfilename) \n",
    "        shutil.move(oldimgfilepath, newimgfilepath) # moving image to test path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 3000x3000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30,30))\n",
    "files = os.listdir(imgtestpath)\n",
    "if len(files) >= 6:\n",
    "    for i in range(6):\n",
    "        test_image=os.path.join(imgtestpath, os.listdir(imgtestpath)[i])\n",
    "        ax=plt.subplot(3,2,i+1)\n",
    "    \n",
    "    # Display actual image\n",
    "        plt.imshow(cv2.imread(test_image)) \n",
    "        plt.xticks([])\n",
    "        plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(imgtestpath)), len(os.listdir(labeltestpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(imgtrainpath)), len(os.listdir(labeltrainpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file '/Users/karpagapriyadhanraj/Desktop/EPITA/Computer vision/Computer_vision/Lab_2/aminal_detection/labels/train/cat_9fd544a838.jpg' does not exist.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/karpagapriyadhanraj/Desktop/EPITA/Computer vision/Computer_vision/Lab_2/aminal_detection/labels/train/cat_9fd544a838.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/computer-vision/lib/python3.10/shutil.py:816\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m     os\u001b[39m.\u001b[39;49mrename(src, real_dst)\n\u001b[1;32m    817\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/karpagapriyadhanraj/Desktop/EPITA/Computer vision/Computer_vision/Lab_2/aminal_detection/labels/train/cat_9fd544a838.jpg' -> '/Users/karpagapriyadhanraj/Desktop/EPITA/Computer vision/Computer_vision/Lab_2/aminal_detection/labels/validation/cat_9fd544a838.jpg'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe file \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mlabelfilepath\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m does not exist.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m shutil\u001b[39m.\u001b[39mmove(imgfilepath, imgdestpath)\n\u001b[0;32m---> 16\u001b[0m shutil\u001b[39m.\u001b[39;49mmove(labelfilepath, labeldestpath)\n",
      "File \u001b[0;32m~/miniconda3/envs/computer-vision/lib/python3.10/shutil.py:836\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    834\u001b[0m         rmtree(src)\n\u001b[1;32m    835\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 836\u001b[0m         copy_function(src, real_dst)\n\u001b[1;32m    837\u001b[0m         os\u001b[39m.\u001b[39munlink(src)\n\u001b[1;32m    838\u001b[0m \u001b[39mreturn\u001b[39;00m real_dst\n",
      "File \u001b[0;32m~/miniconda3/envs/computer-vision/lib/python3.10/shutil.py:434\u001b[0m, in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(dst):\n\u001b[1;32m    433\u001b[0m     dst \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dst, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(src))\n\u001b[0;32m--> 434\u001b[0m copyfile(src, dst, follow_symlinks\u001b[39m=\u001b[39;49mfollow_symlinks)\n\u001b[1;32m    435\u001b[0m copystat(src, dst, follow_symlinks\u001b[39m=\u001b[39mfollow_symlinks)\n\u001b[1;32m    436\u001b[0m \u001b[39mreturn\u001b[39;00m dst\n",
      "File \u001b[0;32m~/miniconda3/envs/computer-vision/lib/python3.10/shutil.py:254\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    252\u001b[0m     os\u001b[39m.\u001b[39msymlink(os\u001b[39m.\u001b[39mreadlink(src), dst)\n\u001b[1;32m    253\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 254\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(src, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m fsrc:\n\u001b[1;32m    255\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    256\u001b[0m             \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(dst, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fdst:\n\u001b[1;32m    257\u001b[0m                 \u001b[39m# macOS\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/karpagapriyadhanraj/Desktop/EPITA/Computer vision/Computer_vision/Lab_2/aminal_detection/labels/train/cat_9fd544a838.jpg'"
     ]
    }
   ],
   "source": [
    "factor=0.2 \n",
    "\n",
    "for file in random.sample(os.listdir(imgtrainpath), int(len(os.listdir(imgtrainpath))*factor)):\n",
    "    basename=os.path.splitext(file)[0]\n",
    "    textfilename=basename+'.jpg'\n",
    "    labelfilepath=os.path.join(labeltrainpath, textfilename)\n",
    "    labeldestpath=os.path.join(labelvalpath, textfilename)\n",
    "    imgfilepath=os.path.join(imgtrainpath, file)\n",
    "    imgdestpath=os.path.join(imgvalpath, file)\n",
    "    if os.path.exists(labelfilepath):\n",
    "    # Move the file\n",
    "        shutil.move(labelfilepath, labeldestpath)\n",
    "    else:\n",
    "        print(f\"The file '{labelfilepath}' does not exist.\")\n",
    "    shutil.move(imgfilepath, imgdestpath)\n",
    "    shutil.move(labelfilepath, labeldestpath)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(imgtrainpath)), len(os.listdir(labeltrainpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(imgvalpath)), len(os.listdir(labelvalpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox_from_label(text_file_path):\n",
    "    bbox_list=[]\n",
    "    with open(text_file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            class_id,x_centre,y_centre,width,height=line.strip().split(\" \")\n",
    "            x1=(float(x_centre)+(float(width)/2))*image_size\n",
    "            x0=(float(x_centre)-(float(width)/2))*image_size\n",
    "            y1=(float(y_centre)+(float(height)/2))*image_size\n",
    "            y0=(float(y_centre)-(float(height)/2))*image_size\n",
    "            \n",
    "            vertices=np.array([[int(x0), int(y0)], [int(x1), int(y0)], \n",
    "                               [int(x1),int(y1)], [int(x0),int(y1)]])\n",
    "            bbox_list.append(vertices)      \n",
    "    return tuple(bbox_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "red=(255,0,0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "newline='\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_1='# Train/val/test sets'+newline\n",
    "\n",
    "# train, val and test path declaration\n",
    "ln_2='train: ' +\"'\"+imgtrainpath+\"'\"+newline\n",
    "ln_3='val: ' +\"'\" + imgvalpath+\"'\"+newline\n",
    "ln_4='test: ' +\"'\" + imgtestpath+\"'\"+newline\n",
    "ln_5=newline\n",
    "ln_6='# Classes'+newline\n",
    "\n",
    "# names of the classes declaration\n",
    "ln_7='names:'+newline\n",
    "ln_8='  0: buffalo'+newline\n",
    "ln_9='  1: elephant'+newline\n",
    "ln_10='  2: rhino'+newline\n",
    "ln_11='  3: zebra'\n",
    "\n",
    "config_lines=[ln_1, ln_2, ln_3, ln_4, ln_5, ln_6, ln_7, ln_8, ln_9, ln_10, ln_11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/karpagapriyadhanraj/Desktop/EPITA/Computer vision/Computer_vision/Lab_2/aminal_detection/config.yaml'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path=os.path.join(curr_path, 'config.yaml')\n",
    "config_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_path, 'w') as f:\n",
    "    f.writelines(config_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3822016  ultralytics.nn.modules.head.Detect           [80, [192, 384, 576]]         \n",
      "YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients, 79.3 GFLOPs\n",
      "\n",
      "Transferred 475/475 items from pretrained weights\n"
     ]
    }
   ],
   "source": [
    "model=YOLO('yolov8m.yaml').load('yolov8m.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.2 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.1 🚀 Python-3.10.13 torch-2.1.2 CPU (Apple M2)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.yaml, data=/Users/karpagapriyadhanraj/Desktop/EPITA/Computer vision/Computer_vision/Lab_2/aminal_detection/config.yaml, epochs=100, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=0.01, iou=0.5, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3778012  ultralytics.nn.modules.head.Detect           [4, [192, 384, 576]]          \n",
      "YOLOv8m summary: 295 layers, 25858636 parameters, 25858620 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages/wandb/sdk/wandb_init.py\", line 1172, in init\n",
      "    wi.setup(kwargs)\n",
      "  File \"/Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages/wandb/sdk/wandb_init.py\", line 306, in setup\n",
      "    wandb_login._login(\n",
      "  File \"/Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages/wandb/sdk/wandb_login.py\", line 317, in _login\n",
      "    wlogin.prompt_api_key()\n",
      "  File \"/Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages/wandb/sdk/wandb_login.py\", line 240, in prompt_api_key\n",
      "    key, status = self._prompt_api_key()\n",
      "  File \"/Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages/wandb/sdk/wandb_login.py\", line 220, in _prompt_api_key\n",
      "    key = apikey.prompt_api_key(\n",
      "  File \"/Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages/wandb/sdk/lib/apikey.py\", line 151, in prompt_api_key\n",
      "    key = input_callback(api_ask).strip()\n",
      "  File \"/Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages/click/termui.py\", line 164, in prompt\n",
      "    value = prompt_func(prompt)\n",
      "  File \"/Users/karpagapriyadhanraj/miniconda3/envs/computer-vision/lib/python3.10/site-packages/click/termui.py\", line 147, in prompt_func\n",
      "    raise Abort() from None\n",
      "click.exceptions.Abort\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "An unexpected error occurred",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAbort\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/computer-vision/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1172\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1171\u001b[0m wi \u001b[39m=\u001b[39m _WandbInit()\n\u001b[0;32m-> 1172\u001b[0m wi\u001b[39m.\u001b[39;49msetup(kwargs)\n\u001b[1;32m   1173\u001b[0m \u001b[39massert\u001b[39;00m wi\u001b[39m.\u001b[39msettings\n",
      "File \u001b[0;32m~/miniconda3/envs/computer-vision/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:306\u001b[0m, in \u001b[0;36m_WandbInit.setup\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m settings\u001b[39m.\u001b[39m_offline \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m settings\u001b[39m.\u001b[39m_noop:\n\u001b[0;32m--> 306\u001b[0m     wandb_login\u001b[39m.\u001b[39;49m_login(\n\u001b[1;32m    307\u001b[0m         anonymous\u001b[39m=\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39manonymous\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    308\u001b[0m         force\u001b[39m=\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mforce\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    309\u001b[0m         _disable_warning\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    310\u001b[0m         _silent\u001b[39m=\u001b[39;49msettings\u001b[39m.\u001b[39;49mquiet \u001b[39mor\u001b[39;49;00m settings\u001b[39m.\u001b[39;49msilent,\n\u001b[1;32m    311\u001b[0m         _entity\u001b[39m=\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mentity\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mor\u001b[39;49;00m settings\u001b[39m.\u001b[39;49mentity,\n\u001b[1;32m    312\u001b[0m     )\n\u001b[1;32m    314\u001b[0m \u001b[39m# apply updated global state after login was handled\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/computer-vision/lib/python3.10/site-packages/wandb/sdk/wandb_login.py:317\u001b[0m, in \u001b[0;36m_login\u001b[0;34m(anonymous, key, relogin, host, force, timeout, _backend, _silent, _disable_warning, _entity)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m key:\n\u001b[0;32m--> 317\u001b[0m     wlogin\u001b[39m.\u001b[39;49mprompt_api_key()\n\u001b[1;32m    319\u001b[0m \u001b[39m# make sure login credentials get to the backend\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/computer-vision/lib/python3.10/site-packages/wandb/sdk/wandb_login.py:240\u001b[0m, in \u001b[0;36m_WandbLogin.prompt_api_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprompt_api_key\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 240\u001b[0m     key, status \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prompt_api_key()\n\u001b[1;32m    241\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m==\u001b[39m ApiKeyStatus\u001b[39m.\u001b[39mNOTTY:\n",
      "File \u001b[0;32m~/miniconda3/envs/computer-vision/lib/python3.10/site-packages/wandb/sdk/wandb_login.py:220\u001b[0m, in \u001b[0;36m_WandbLogin._prompt_api_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 220\u001b[0m     key \u001b[39m=\u001b[39m apikey\u001b[39m.\u001b[39;49mprompt_api_key(\n\u001b[1;32m    221\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_settings,\n\u001b[1;32m    222\u001b[0m         api\u001b[39m=\u001b[39;49mapi,\n\u001b[1;32m    223\u001b[0m         no_offline\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_settings\u001b[39m.\u001b[39;49mforce \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_settings \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    224\u001b[0m         no_create\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_settings\u001b[39m.\u001b[39;49mforce \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_settings \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[1;32m    226\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    227\u001b[0m     \u001b[39m# invalid key provided, try again\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/computer-vision/lib/python3.10/site-packages/wandb/sdk/lib/apikey.py:151\u001b[0m, in \u001b[0;36mprompt_api_key\u001b[0;34m(settings, api, input_callback, browser_callback, no_offline, no_create, local)\u001b[0m\n\u001b[1;32m    148\u001b[0m     wandb\u001b[39m.\u001b[39mtermlog(\n\u001b[1;32m    149\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou can find your API key in your browser here: \u001b[39m\u001b[39m{\u001b[39;00mapp_url\u001b[39m}\u001b[39;00m\u001b[39m/authorize\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m     )\n\u001b[0;32m--> 151\u001b[0m     key \u001b[39m=\u001b[39m input_callback(api_ask)\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m    152\u001b[0m write_key(settings, key, api\u001b[39m=\u001b[39mapi)\n",
      "File \u001b[0;32m~/miniconda3/envs/computer-vision/lib/python3.10/site-packages/click/termui.py:164\u001b[0m, in \u001b[0;36mprompt\u001b[0;34m(text, default, hide_input, confirmation_prompt, type, value_proc, prompt_suffix, show_default, err, show_choices)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m     value \u001b[39m=\u001b[39m prompt_func(prompt)\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m value:\n",
      "File \u001b[0;32m~/miniconda3/envs/computer-vision/lib/python3.10/site-packages/click/termui.py:147\u001b[0m, in \u001b[0;36mprompt.<locals>.prompt_func\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    146\u001b[0m     echo(\u001b[39mNone\u001b[39;00m, err\u001b[39m=\u001b[39merr)\n\u001b[0;32m--> 147\u001b[0m \u001b[39mraise\u001b[39;00m Abort() \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mAbort\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mtrain(data\u001b[39m=\u001b[39;49mconfig_path, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, iou\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m, conf\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/computer-vision/lib/python3.10/site-packages/ultralytics/engine/model.py:390\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mhub_session \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession  \u001b[39m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m    391\u001b[0m \u001b[39m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[39mif\u001b[39;00m RANK \u001b[39min\u001b[39;00m (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/computer-vision/lib/python3.10/site-packages/ultralytics/engine/trainer.py:208\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m         ddp_cleanup(\u001b[39mself\u001b[39m, \u001b[39mstr\u001b[39m(file))\n\u001b[1;32m    207\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_train(world_size)\n",
      "File \u001b[0;32m~/miniconda3/envs/computer-vision/lib/python3.10/site-packages/ultralytics/engine/trainer.py:322\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[39mif\u001b[39;00m world_size \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    321\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setup_ddp(world_size)\n\u001b[0;32m--> 322\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_train(world_size)\n\u001b[1;32m    324\u001b[0m nb \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loader)  \u001b[39m# number of batches\u001b[39;00m\n\u001b[1;32m    325\u001b[0m nw \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mround\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mwarmup_epochs \u001b[39m*\u001b[39m nb), \u001b[39m100\u001b[39m) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mwarmup_epochs \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m  \u001b[39m# warmup iterations\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/computer-vision/lib/python3.10/site-packages/ultralytics/engine/trainer.py:235\u001b[0m, in \u001b[0;36mBaseTrainer._setup_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Builds dataloaders and optimizer on correct rank process.\"\"\"\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[39m# Model\u001b[39;00m\n\u001b[0;32m--> 235\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_callbacks(\u001b[39m\"\u001b[39;49m\u001b[39mon_pretrain_routine_start\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    236\u001b[0m ckpt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msetup_model()\n\u001b[1;32m    237\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/computer-vision/lib/python3.10/site-packages/ultralytics/engine/trainer.py:171\u001b[0m, in \u001b[0;36mBaseTrainer.run_callbacks\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Run all existing callbacks associated with a particular event.\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mget(event, []):\n\u001b[0;32m--> 171\u001b[0m     callback(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/computer-vision/lib/python3.10/site-packages/ultralytics/utils/callbacks/wb.py:111\u001b[0m, in \u001b[0;36mon_pretrain_routine_start\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_pretrain_routine_start\u001b[39m(trainer):\n\u001b[1;32m    110\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Initiate and start project if module is present.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m     wb\u001b[39m.\u001b[39mrun \u001b[39mor\u001b[39;00m wb\u001b[39m.\u001b[39;49minit(project\u001b[39m=\u001b[39;49mtrainer\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mproject \u001b[39mor\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mYOLOv8\u001b[39;49m\u001b[39m\"\u001b[39;49m, name\u001b[39m=\u001b[39;49mtrainer\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mname, config\u001b[39m=\u001b[39;49m\u001b[39mvars\u001b[39;49m(trainer\u001b[39m.\u001b[39;49margs))\n",
      "File \u001b[0;32m~/miniconda3/envs/computer-vision/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1214\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1212\u001b[0m             wandb\u001b[39m.\u001b[39mtermerror(\u001b[39m\"\u001b[39m\u001b[39mAbnormal program exit\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1213\u001b[0m             os\u001b[39m.\u001b[39m_exit(\u001b[39m1\u001b[39m)\n\u001b[0;32m-> 1214\u001b[0m         \u001b[39mraise\u001b[39;00m Error(\u001b[39m\"\u001b[39m\u001b[39mAn unexpected error occurred\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merror_seen\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[39mreturn\u001b[39;00m run\n",
      "\u001b[0;31mError\u001b[0m: An unexpected error occurred"
     ]
    }
   ],
   "source": [
    "results=model.train(data=config_path, epochs=100, iou=0.5, conf=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_map50(trainedmodel, data_path, dataset='val'):\n",
    "    metrics=trainedmodel.val(data=data_path, split=dataset)\n",
    "    map50=round(metrics.box.map50, 3)\n",
    "    print(\"The mAP of model for all images on {0} dataset is {1}\".format(dataset,map50))\n",
    "    return metrics, map50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_curves(root_path):\n",
    "    plt.figure(figsize=(50,50))\n",
    "    \n",
    "    #displaying p curve\n",
    "    p_curve=cv2.imread(os.path.join(root_path,'P_curve.png'))\n",
    "    ax=plt.subplot(5,1,1)\n",
    "    plt.imshow(p_curve)\n",
    "    \n",
    "    #displaying r curve\n",
    "    r_curve=cv2.imread(os.path.join(root_path,'R_curve.png'))\n",
    "    ax=plt.subplot(5,1,2)\n",
    "    plt.imshow(r_curve)\n",
    "    \n",
    "    #displaying pr curve\n",
    "    pr_curve=cv2.imread(os.path.join(root_path,'PR_curve.png'))\n",
    "    ax=plt.subplot(5,1,3)\n",
    "    plt.imshow(pr_curve)\n",
    "    \n",
    "    #displaying f1 curve\n",
    "    f1_curve=cv2.imread(os.path.join(root_path,'F1_curve.png'))\n",
    "    ax=plt.subplot(5,1,4)\n",
    "    plt.imshow(f1_curve)\n",
    "    \n",
    "    #displaying confusion matrix\n",
    "    confusion_matrix=cv2.imread(os.path.join(root_path,'confusion_matrix.png'))\n",
    "    ax=plt.subplot(5,1,5)\n",
    "    plt.imshow(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.1 🚀 Python-3.10.13 torch-2.1.2 CPU (Apple M2)\n",
      "YOLOv8m summary (fused): 218 layers, 25842076 parameters, 14796 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/karpagapriyadhanraj/Desktop/EPITA/Computer vision/Computer_vision/Lab_2/aminal_detection/labels/train... 0 images, 478 backgrounds, 0 corrupt: 100%|██████████| 478/478 [00:00<00:00, 10036.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ No labels found in /Users/karpagapriyadhanraj/Desktop/EPITA/Computer vision/Computer_vision/Lab_2/aminal_detection/labels/train.cache. See https://docs.ultralytics.com/datasets/detect for dataset formatting guidance.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/karpagapriyadhanraj/Desktop/EPITA/Computer vision/Computer_vision/Lab_2/aminal_detection/labels/train.cache\n",
      "WARNING ⚠️ No labels found in /Users/karpagapriyadhanraj/Desktop/EPITA/Computer vision/Computer_vision/Lab_2/aminal_detection/labels/train.cache, training may not work correctly. See https://docs.ultralytics.com/datasets/detect for dataset formatting guidance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [05:12<00:00, 10.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        478          0          0          0          0          0\n",
      "WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.8ms preprocess, 639.3ms inference, 0.0ms loss, 11.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
      "The mAP of model for all images on train dataset is 0.0\n"
     ]
    }
   ],
   "source": [
    "train_metrics, train_map50=evaluate_map50(model, config_path, dataset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path=os.path.join(curr_path, 'runs', 'detect', 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.1 🚀 Python-3.10.13 torch-2.1.2 CPU (Apple M2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/karpagapriyadhanraj/Desktop/EPITA/Computer vision/Computer_vision/Lab_2/aminal_detection/labels/validation... 0 images, 8 backgrounds, 0 corrupt: 100%|██████████| 8/8 [00:00<00:00, 6258.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ No labels found in /Users/karpagapriyadhanraj/Desktop/EPITA/Computer vision/Computer_vision/Lab_2/aminal_detection/labels/validation.cache. See https://docs.ultralytics.com/datasets/detect for dataset formatting guidance.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/karpagapriyadhanraj/Desktop/EPITA/Computer vision/Computer_vision/Lab_2/aminal_detection/labels/validation.cache\n",
      "WARNING ⚠️ No labels found in /Users/karpagapriyadhanraj/Desktop/EPITA/Computer vision/Computer_vision/Lab_2/aminal_detection/labels/validation.cache, training may not work correctly. See https://docs.ultralytics.com/datasets/detect for dataset formatting guidance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8          0          0          0          0          0\n",
      "WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 1.4ms preprocess, 435.3ms inference, 0.0ms loss, 11.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n",
      "The mAP of model for all images on val dataset is 0.0\n"
     ]
    }
   ],
   "source": [
    "val_metrics, val_map50=evaluate_map50(model, config_path, dataset='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path=os.path.join(curr_path, 'runs', 'detect', 'val2') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 3000x3000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30,30))\n",
    "m=random.randint(0, 17) # Selecting random image number from 18 images in test dataset\n",
    "files = os.listdir(imgtestpath)\n",
    "if files:\n",
    "    m = random.randint(0, len(files) - 1)\n",
    "    for i in range(1,6,2):\n",
    "        test_image=os.path.join(imgtestpath, os.listdir(imgtestpath)[m])\n",
    "        ax=plt.subplot(3,2,i)\n",
    "        \n",
    "    # Display actual image\n",
    "    plt.imshow(cv2.imread(test_image)) \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(\"Actual image\", fontsize = 40)\n",
    "    \n",
    "    # Predict \n",
    "    res = model(test_image)\n",
    "    res_plotted = res[0].plot()\n",
    "    ax=plt.subplot(3,2,i+1)\n",
    "    \n",
    "    # Display image with predictions\n",
    "    plt.imshow(res_plotted)\n",
    "    plt.title(\"Image with predictions\", fontsize = 40)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    m=m+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer-vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
